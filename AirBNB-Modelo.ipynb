{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Projeto AirBNB</center>\n",
    "  <center>Previsão de preços das acomodações em Boston/MA - USA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Entendendo o desafio:\n",
    "\n",
    "##### 1.1. O que é o Airbnb?\n",
    "\n",
    "O <a href=\"www.airbnb.com\">Airbnb</a> é um serviço que permite que pessoas do mundo inteiro ofereçam suas casas para usuários que buscam acomodações mais em conta em qualquer lugar do mundo. No Airbnb, é possível oferecer um apenas um quarto ou a casa completa a outros usuários, como também alugar um espaço, caso seja a sua necessidade ou interesse. Usado por turistas, viajantes e profissionais em trânsito, o grande apelo do serviço está nos custos mais baixos e na facilidade de uso: alugar um imóvel sem muita burocracia.\n",
    "\n",
    "Caso o usuário precise alugar um espaço, basta fazer uma busca (tanto no aplicativo como pelo site) para encontrar opções na cidade em que deseja. É possível escolher a partir de preços, observar as datas disponíveis (há casos de usuários que oferecem suas casas e cômodos por períodos curtos e específicos apenas), a partir das resenhas de outros usuários (você é classificado e pode classificar os proprietários) e assim por diante.\n",
    "Para alugar uma acomodação, a mecânica é basicamente a mesma: é preciso cadastrar o imóvel disponível, especificando informações práticas a seu respeito (é a casa inteira ou só um quarto? O período é de um feriado específico, algumas semanas em que você vai viajar? O ano inteiro?), deve colocar fotos que mostrem o espaço e descrevê-lo da melhor maneira possível. Detalhes como endereço e localização também são muito importantes.\n",
    "\n",
    "O Airbnb começou em 2008, quando dois designers que tinham um espaço sobrando hospedaram três viajantes que procuravam um lugar para ficar. Agora, milhões de anfitriões e viajantes optam por criar uma conta gratuita no Airbnb para que possam anunciar seu espaço e reservar acomodações únicas, em qualquer lugar do mundo. Além disso, os anfitriões de experiências do Airbnb compartilham suas paixões e interesses com viajantes e moradores locais.\n",
    "\n",
    "##### 1.2. Objetivo:\n",
    "\n",
    "Construir um modelo de previsão de preço que permita que o proprietário do imóvel (<i>host</i>) saiba quanto deve cobrar com base nas características do seu bem.\n",
    "\n",
    "Ou ainda, que um locatário saiba se o preço que está sendo cobrado é justo para o imóvel escolhido.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extração/Obtenção de dados:\n",
    "\n",
    "A base de dados utilizada nesse modelo pode ser baixado diretamente no site do <a href=\"www.kaggle.com\">Kaggle</a>: <a href=\"https://www.kaggle.com/katerynaosadchuk/boston-airbnb-listings?select=boston_listings.csv\">Clique Aqui para baixar!</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2.1. Importando a biblioteca e a base de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('boston_listings.csv')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Ajuste/Limpeza de dados:\n",
    "\n",
    "Aqui vamos analisar quais as informações que são importantes manter no dataframe, excluindo tudo que não demonstrar ser necesário.\n",
    "\n",
    "Para analisar melhor, vamos criar uma planilha em excel com os 300 primeiros registros para poder fazer a análise das informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(list(df.columns)) # Esse código nos mostra todas as colunas do dataframe, porém não acessamos o conteúdo.\n",
    "                        # Daí a necessidade de criar o excel com os primeiros registros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando os Excel com os primeiros 300 registros. O arquivo fica salvo na mesma pasta do notebook.\n",
    "df.head(300).to_excel('primeiros300.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise, temos alguns tipos de colunas que iremos excluir:\n",
    "- as que não tenham informações relevantes para o modelo de predição, por ex: ids e links;\n",
    "- as que tenham informações parecidas com a de outras colunas;\n",
    "- as colunas que sejam de texto livre preenchidas pelo *host*;\n",
    "- colunas em que todas ou quase todas as informações são iguais;\n",
    "\n",
    "Com isso, ficamos com as seguintes colunas:\n",
    "\n",
    "'host_response_time',\t'host_response_rate',\t'host_is_superhost',\t'host_total_listings_count',\t'latitude',\t'longitude',\t'property_type',\t'room_type',\t'accommodates',\t'bathrooms',\t'bedrooms',\t'beds',\t'bed_type',\t'amenities_dict',\t'price',\t'cleaning_fee',\t'number_of_reviews',\t'review_scores_rating',\t'review_scores_accuracy',\t'review_scores_cleanliness',\t'review_scores_checkin',\t'review_scores_communication',\t'review_scores_location',\t'review_scores_value',\t'instant_bookable',\t'is_business_travel_ready',\t'cancellation_policy'\n",
    "\n",
    "###### 3.1. Criando o dataframe apenas com as colunas necessárias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colunas = ['host_response_time', 'host_response_rate', 'host_is_superhost', 'host_total_listings_count', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities_dict', 'price', 'cleaning_fee', 'number_of_reviews', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'instant_bookable', 'is_business_travel_ready', 'cancellation_policy']\n",
    "\n",
    "#Aqui criaremos um filtro para o dataframe aparecer só as colunas que colocamos em uma lista na variável acima\n",
    "\n",
    "df = df.loc[:, colunas]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O dataset original tinha 51 colunas, com a análise exploratória ficamos com 27.\n",
    "\n",
    "###### 3.2. Tratando as informações vazias (NaN):\n",
    "\n",
    "Temos que fazer essa análise pois as informações vazias podem atrapalhar o modelo de previsão. Analisando abaixo quais as colunas que contem muita falta de informação para podermos excluí-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos algumas colunas com mais de 10% de informações vazias, com isso iremos excluir todas elas da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#excluindo as colunas com muitos dados vazios.\n",
    "\n",
    "for coluna in df:\n",
    "    if df[coluna].isnull().sum() >= 350:\n",
    "        df = df.drop(coluna, axis=1)\n",
    "\n",
    "        \n",
    "display(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse novo tratamento, nos restaram **17 colunas** na base de dados que irá para o modelo de previsão.\n",
    "\n",
    "Para os outros dados, como o número de NaNs é pequeno, iremos excluir as linhas que tenham falta das informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df)\n",
    "df = df.dropna()\n",
    "print(df.shape)\n",
    "#print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos um dataframe com **3820 linhas** e as mesmas **17 colunas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3.3. Verificando o tipo de dados:\n",
    "\n",
    "Aqui vamos verificar como o pandas reconheceu o tipo do dado, pois, algumas vezes ele reconhece um número (int) como um texto (string) e aí atrapalha o processamento.\n",
    "\n",
    "Após a análise, iremos corrigir eventuais erros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)\n",
    "#abaixo vemos que o preço, que deveria ser um float, retornou como objeto em virtude do simbolo $\n",
    "#para corrigir teremos que excluir o $ e a virgula que consta como separador de milhar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.replace('$', '') #retira o $\n",
    "df['price'] = df['price'].str.replace(',', '') #retira a ,\n",
    "df['price'] = df['price'].astype(np.float32, copy=False) #transforma em float\n",
    "print(df.dtypes) #para confirmar que foi efetuada a mudança\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Análise exploratória:\n",
    "\n",
    "Vamos percorrer todas as colunas que sobraram e analisar os valores que contem ali dentro. Qual é o maior e o menor valor, em que faixa estão a maioria dos valores e etc.\n",
    "\n",
    "Aqui teremos que usar alguns conceitos de estatística que serão explicados a medida que forem sendo usados.\n",
    "\n",
    "Primeiro, vamos ver a correlação entre os itens, após utilizaremos o conceito estatistico de quartil.\n",
    "\n",
    "O objetivo final da análise exploratória é descobrir alguma informação muito discrepante (outliers), para depois decidir se iremos manter ou não esses outliers.\n",
    "\n",
    "Tais análises irão iniciar com as colunas númericas como o preço, depois iremos para quartos, camas e hóspedes. Por fim, iremos analisar as colunas com texto para definir quais fazem sentido em continuar na análise ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.1. Correlação de informações:\n",
    "\n",
    "É como um item se correlaciona com o outro, por exemplo, quando se tem mais quartos o preço é maior. Nesse caso, seria uma correlação positiva.\n",
    "\n",
    "Ou quando aumento a quantidade mínima de diárias o preço da diária abaixa, aí seria uma correlação negativa.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#demonstrando a mesma informação com um mapa de calor\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='Reds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos aqui que não há nenhuma correlação tão forte que possa atrapalhar nosso modelo de previsão, logo deixaremos todas as colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2. Quartil:\n",
    "\n",
    "\n",
    "\n",
    "Após ver a correlação, vamos usar o conceito de **quartil**, ou seja, vamos pegar nossos dados e dividi-los em quatro quartis.\n",
    "\n",
    "Para excluir os **outliers** (dados muito discrepantes), vamos excluir os que estejam abaixo do Q1 - 1,5x Amplitude e acima do Q3 + 1,5x Amplitude.\n",
    "\n",
    "Amplitude é a diferença entre o Q1 e o Q3.\n",
    "\n",
    "Vamos definir algumas funções para ajudar na análise de **outliers** das colunas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limites(coluna):\n",
    "    q1 = coluna.quantile(0.25)\n",
    "    q3 = coluna.quantile(0.75)\n",
    "    amplitude = q3 - q1\n",
    "    return q1 - 1.5 * amplitude, q3 + 1.5 * amplitude\n",
    "\n",
    "def excluir_outliers(df, nome_coluna):\n",
    "    linhas = df.shape[0]\n",
    "    lim_inf, lim_sup = limites(df[nome_coluna])\n",
    "    df = df.loc[(df[nome_coluna] >= lim_inf) & (df[nome_coluna] <= lim_sup), :] #filtrando o dataframe\n",
    "    linhas_removidas = linhas - df.shape[0]\n",
    "    return df, linhas_removidas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagrama_caixa(coluna):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(15,5)\n",
    "    sns.boxplot(x=coluna, ax=ax1)\n",
    "    ax2.set_xlim(limites(coluna))\n",
    "    sns.boxplot(x=coluna, ax=ax2)\n",
    "    \n",
    "def histograma(coluna):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    sns.distplot(coluna, hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.1. Analisando a coluna de preços (price):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diagrama_caixa(df['price'])\n",
    "histograma(df['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **gráfico superior esquerdo**, mostra todos os preços de diárias, com isso, podemos ver que temos preços até próximo a US$ 10000 (dez mil dólares) por dia.\n",
    "\n",
    "Já o **gráfico superior direito** mostra a variação de preços dentro dos limites definidos anteriormente. Logo, verificamos que ficou os preços entre 0 a pouco mais de 300 dólares a diária. \n",
    "\n",
    "Levando isso em consideração, temos que tomar a decisão se usaremos todos os dados ou se iremos excluir os **outliers**. Para tomar essa decisão, precisamos de uma análise qualitativa.\n",
    "\n",
    "Como nosso objetivo é verificar preço de diárias de imóveis \"comuns\" nós provavelmente iremos excluir os outliers, pois, um imóvel de cerca de 10 mil dólares a diária deve ser uma mega mansão super luxuosa e que só irá atrapalhar o modelo de predição.\n",
    "\n",
    "Eu disse provavelmente por que teremos que ver a quantidade de dados que serao excluídos, pois se forem um número muito alto, talvez não possamos excluir, já que isso vai indicar que realmente temos muitas unidades com valores acima dos nossos limites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, linhas_removidas = excluir_outliers(df, 'price') \n",
    "print(f'{linhas_removidas} linhas removidas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a quantidade de linhas removidas não foi tão substancial, vamos deixar elas excluidas para não atrapalhar nosso modelo.\n",
    "\n",
    "Vamos ver como fica nosso gráfico de histograma após a exclusão dos outliers da coluna price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma(df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "# ainda temos 3596 linhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos continuar analisando as outras colunas para saber se poderemos excluir os outliers ou não.\n",
    "\n",
    "###### 4.2.2. Analisando a coluna de host_total_listings_count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diagrama_caixa(df['host_total_listings_count'])\n",
    "histograma(df['host_total_listings_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, vemos no histograma que a quase totalidade possui um imóvel listado, então, em vez de usar um histograma, vamos criar um gráfico de barras que vai dizer quantas imóveis as pessoas tem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafico_barra(coluna):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    ax = sns.barplot(x=coluna.value_counts().index, y=coluna.value_counts())\n",
    "    ax.set_xlim(limites(coluna))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grafico_barra(df['host_total_listings_count'])\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=df['host_total_listings_count'].value_counts().index, y=df['host_total_listings_count'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, linhas_removidas = excluir_outliers(df, 'host_total_listings_count') \n",
    "print(f'{linhas_removidas} linhas removidas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.3. Analisando a coluna de accommodates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagrama_caixa(df['accommodates'])\n",
    "grafico_barra(df['accommodates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, linhas_removidas = excluir_outliers(df, 'accommodates') \n",
    "print(f'{linhas_removidas} linhas removidas')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.4. Analisando a coluna de bathrooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagrama_caixa(df['bathrooms'])\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=df['bathrooms'].value_counts().index, y=df['bathrooms'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df, linhas_removidas = excluir_outliers(df, 'bathrooms') \n",
    "#print(f'{linhas_removidas} linhas removidas')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o limite que o cálculo de quartil chegou para banheiros foi de apenas 1. Acho melhor não excluir, tendo em vista que imóveis com mais banheiros devem sim modificar o preço, bem como é bem comum um imóvel ter mais banheiros. Por isso, como as linhas já foram excluídas, irei rodar novamente o código, deixando a parte da exclusão como comentário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.5. Analisando a coluna de bedrooms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diagrama_caixa(df['bedrooms'])\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(x=df['bedrooms'].value_counts().index, y=df['bedrooms'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelo mesmo motivo que em banheiros, como os limites definidos para quartos foi de apenas um. Também não excluirei os outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.6. Analisando a coluna de beds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrama_caixa(df['beds'])\n",
    "grafico_barra(df['beds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, linhas_removidas = excluir_outliers(df, 'beds') \n",
    "print(f'{linhas_removidas} linhas removidas')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.7. Analisando a coluna de quantidade de reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrama_caixa(df['number_of_reviews'])\n",
    "grafico_barra(df['number_of_reviews'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o modelo vai prever o valor de um novo imóvel, é melhor tirar essa coluna, pois quem for incluir seu imóvel não vai ter nenhum review no início."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop('number_of_reviews', axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, finalizamos nossa análise exploratória das colunas numéricas. Terminamos com 2661 linhas e 16 colunas.\n",
    "\n",
    "Passaremos agora para as colunas de texto. Esse tipo de coluna geralmente é uma categoria, por exemplo, se é casas ou apartamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3. Analisando as colunas de texto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features de texto serão separados pelas colunas de verdadeiro e falso (true / false) e os que tem algumas categorias de texto.\n",
    "\n",
    "Os verdadeiro e falso não precisa muito tratamento, as outras sim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.1. Tipo de propriedade (property_type):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, teremos que ver a quantidade de que cada texto (categoria) está na tabela. Para isso iremos mostrar através de um print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['property_type'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('property_type', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos mudar algumas categorias que apresentam menos resultados, agrupando tudo em uma coluna que se chamará Outros.\n",
    "\n",
    "No caso, escolhemos manter todas as categorias de cima para baixo até o Loft. A categoria Hotel já fará parte da nova categoria Outros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tipo_imovel = df['property_type'].value_counts()\n",
    "\n",
    "agrupar = []\n",
    "for tipo in tipo_imovel.index:\n",
    "    if tipo_imovel[tipo] < 30:\n",
    "        agrupar.append(tipo)\n",
    "#print(agrupar)\n",
    "\n",
    "for tipo in agrupar:\n",
    "    df.loc[df['property_type'] == tipo, 'property_type'] = 'Outros'\n",
    "    \n",
    "print(df['property_type'].value_counts())\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('property_type', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.2. Tipo de sala (room_type):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iremos fazer praticamente a mesma análise do item anterior. Iremos verificar os tipos e agrupar caso esteja muito pulverizado algum tipo de informação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['room_type'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('room_type', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste caso, como são poucas categorias (4 no total) e ainda duas com um quantidade de repetição muito baixa, entendemos que isso não atrapalhará o modelo, logo deixaremos essa coluna inalterada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.3. Tipo de cama (bed_type):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['bed_type'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('bed_type', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos o mesmo caso que aconteceu com o room_type. Então vamos deixar as categorias inalteradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.4. Política de cancelamento (cancellation_policy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['cancellation_policy'].value_counts())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('cancellation_policy', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, como temos duas categorias bem parecidas, vamos juntá-las e criar uma categoria chamada super_strict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo_cancelamento = df['cancellation_policy'].value_counts()\n",
    "\n",
    "agrupar = []\n",
    "for tipo in tipo_cancelamento.index:\n",
    "    if tipo_cancelamento[tipo] < 30:\n",
    "        agrupar.append(tipo)\n",
    "#print(agrupar)\n",
    "\n",
    "for tipo in agrupar:\n",
    "    df.loc[df['cancellation_policy'] == tipo, 'cancellation_policy'] = 'super_strict'\n",
    "    \n",
    "print(df['cancellation_policy'].value_counts())\n",
    "plt.figure(figsize=(15,5))\n",
    "grafico = sns.countplot('cancellation_policy', data=df)\n",
    "grafico.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.5. Amenities (amenities_dict):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['amenities_dict'].iloc[1])\n",
    "\n",
    "print(type(df['amenities_dict'].iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, apesar de parecer um dicionário, no nosso banco de dados as informações dos amenities são uma string. \n",
    "\n",
    "Então, primeiramente vamos ter que transformar em um dicionário, para depois saber quantos amenities tem no imóvel e colocar esse número de amenities em uma coluna separada.\n",
    "\n",
    "A razão disso, é que não queremos analisar item por item de cada apartamento e sim quantos itens cada apartamento tem, ou seja, o parametro será a quantidade de amenities e não cada amenitie individualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['amenities_dict'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "for i, amenidades in enumerate(df['amenities_dict']):\n",
    "    df['amenities_dict'][i] = ast.literal_eval(amenidades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df['amenities_dict'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já mudamos todos as informações para um dicionário, vamos conseguir contar quantas amenidades cada imóvel possui."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(Amenindades=0)\n",
    "\n",
    "for i in range(len(df['amenities_dict'])):\n",
    "    count = 0\n",
    "    try:\n",
    "        for j in df['amenities_dict'][i].values():\n",
    "            if j > 0:\n",
    "                count += 1                \n",
    "        print(count)\n",
    "        df['Amenindades'][i] = count\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "#df = df.drop(df[2661:].index)\n",
    "print(df['Amenindades'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df.Amenindades == 0].index)\n",
    "print(df['Amenindades'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que foi criada a coluna amenidades, com o número de itens que cada uma possuia, podemos excluir a coluna amenities_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('amenities_dict', axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coluna Amenidades agora é uma coluna numérica, então teremos que fazer a análise dela para ver se tem outliers para ser excluída ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.3.5.1. Analisando a coluna Amenidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrama_caixa(df['Amenindades'])\n",
    "grafico_barra(df['Amenindades'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifica-se facilmente que a grande maioria possui 23 amenidades e que os limites definidos ficaram entre 10 e 40, agora vamos excluir os outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, linhas_removidas = excluir_outliers(df, 'Amenindades') \n",
    "print(f'{linhas_removidas} linhas removidas')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Visualização de mapa das propriedades:\n",
    "\n",
    "Iremos usar a biblioteca plotly, pois ela cria um gráfico interativo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "amostra = df.sample(n=1700)\n",
    "centro_mapa = {'lat': amostra.latitude.mean(), 'lon': amostra.longitude.mean()}\n",
    "mapa = px.density_mapbox(amostra, lat='latitude', lon='longitude', z='price', radius=6, center=centro_mapa, zoom=11, mapbox_style='open-street-map')\n",
    "mapa.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Encoding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O encoding irá facilitar o treino do modelo de previsão, já que tais modelos só funcionam com variáveis numéricas.\n",
    "\n",
    "Ou seja, tudo que for texto, teremos que transformar em números."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.1. Transformando as colunas de Verdadeiro (True) e Falso (False):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, iremos transformar as colunas host_is_superhost, instant_bookable e is_business_travel_ready que tem como resposta verdadeiro em falso em respostas da seguinte forma:\n",
    "1 - Verdadeiro (True)\n",
    "0 - Falso (False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#criando uma coluna com as categorias de verdadeiro e falso\n",
    "colunas_tf = ['host_is_superhost', 'instant_bookable', 'is_business_travel_ready' ]\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "for coluna in colunas_tf:\n",
    "    df_encoded.loc[df_encoded[coluna] == 't', coluna] = 1\n",
    "    df_encoded.loc[df_encoded[coluna] == 'f', coluna] = 0\n",
    "    #               ^       linha filtrada  ˆ \n",
    "\n",
    "print(df_encoded.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dataframe df_encoded já podemos ver que o t e f viraram 1 e 0, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2. Transformando as colunas com diversas categorias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, não podemos simplesmente colocar os números, pois o modelo pode entender que há uma relação de ordens, ou que o item 4 é o dobro do item 2, sendo que no texto são apenas categorias diferentes que não tem nenhum correlação.\n",
    "\n",
    "Por isso, iremos criar as **variáveis Dummies**. Na prática, substituiremos a informação da categoria por uma nova coluna (nova categoria) que terá a informação se aquela informação que estava inserida na categoria é verdadeira ou falsa.\n",
    "\n",
    "Por exemplo, em vez da informação Real_bed na categoria Beds, teremos uma categoria Real_Bed que dirá se a informação é verdadeira ou falsa (1 ou 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coluna_categorias = ['property_type', 'room_type','bed_type', 'cancellation_policy']\n",
    "\n",
    "df_encoded = pd.get_dummies(data=df_encoded, columns=coluna_categorias)\n",
    "display(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, finalizamos o tratamento dos dados.\n",
    "\n",
    "Agora partiremos para o treinamento do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Teoria para o Modelo de Previsão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É aqui que entra o Machine Learning.\n",
    "\n",
    "Vamos seguir alguns passos para criar e treinar o modelo.\n",
    "\n",
    "Passo 1: definir se é Classificação ou Regressão; <br>\n",
    "Passo 2: Escolher as métricas para avaliar o modelo;<br>\n",
    "Passo 3: Escolher quais modelos vamos usar/testar;<br>\n",
    "Passo 4: Treinar os modelos e testar;<br>\n",
    "Passo 5: Comparar os resukltados dos modelos e escolher o melhor;<br>\n",
    "Passo 6: Analisar o melhor modelos mais a fundo;<br>\n",
    "Passo 7: Fazer os ajustes no melhor modelo<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.1. Classificação ou Regressão:\n",
    "\n",
    "**Classificação**: É quando o modelo de machine learning vai separar em categorias, por exemplo: um diagnóstico, definir se aquele email é um SPAM, etc.\n",
    "\n",
    "**Regressão**: Nesse caso, o modelo vai chegar a um número específico, por exemplo: o preço de determinado item, a velocidade, etc.\n",
    "\n",
    "Com isso, fica claro que *in casu* temos um problema de **regressão**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.2. Métricas para avaliar o modelo:\n",
    "\n",
    "O melhor modelo é o que erra menos ou o que acerta mais?\n",
    "\n",
    "Iremos usar duas métricas para avaliar o melhor modelo:\n",
    "\n",
    "**R²**: \n",
    "Vai de 0 a 1 -> Quanto maior melhor.\n",
    "Mede \"o quanto\" dos valores o modelo consegue explicar.\n",
    "Exemplo: 92% significa que o modelo consegue explicar 92% da variância dos dados a partir das informações que entregamos a ele.\n",
    "\n",
    "**RSME (Erro quadrático médio ou Raiz do Erro Quadrático Médio)**:\n",
    "Pode ser qualquer valor.\n",
    "Quanto menor o valor, será melhor o modelo.\n",
    "Mede o quanto o modelo erra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.3. Escolha dos modelos que vamos usar/testar:\n",
    "\n",
    "- **Linear Regression (Regressão Linear)**: é um método estatistico que usa a relação entre os dados para \"desenhar\" uma linha reta entre eles. Essa linha poderá ser usada para prever valores futuros;\n",
    "- **Random Forest Regressor**: é um modelo de árvore de decisão, onde cada pergunta vai separando os valores em diversas categorias até chegar na resposta mais provável possível. No Random Forest, ele vai pegar todos os dados e criar várias árvores de decisão com pedaços menores de dados e depois vai fazer uma média com as respostas prováveis;\n",
    "- **Extra Trees**: também é um modelo de árvore de decisão e faz a mesma coisa que o Random Forest, com a diferença que no Extra Trees, ele faz uma pergunta aleatória, já no Random Forest ele faz a melhor pergunta possível.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.4. Treinar e testar os modelos:\n",
    "\n",
    "Primeiro temos que separar os dados aleatoriamente em 2 conjutos:\n",
    "- Treino\n",
    "- Teste\n",
    "\n",
    "O treino são os dados que o modelo irá usar para aprender. <br>\n",
    "O teste são os dados que usamos para ver se o modelo aprendeu bem.\n",
    "\n",
    "Exemplo: 80% de dados para o treinoe 20% para o teste.\n",
    "\n",
    "Sempre avaliamos o resultado nos testes para não correr o risco de overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.5. Comparar os Resultados do Teste e escolher o vencedor:\n",
    "\n",
    "Iremos calcular o R² e RSME para cada modelo e escolheremos uma métrica para ser a principal.\n",
    "\n",
    "A outra métrica será considerado critério de desempate ou para comparar modelos com resultados principais parecidos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.6. Analisar o melhor modelo mais a fundo:\n",
    "\n",
    "Após escolher o vencedor, vamos analisá-lo mais a fundo buscando ver como ele funciona e identificar a importancia de cada feature. Com isso, buscamos oportunidades de melhoria do próprio modelo vencedor.\n",
    "\n",
    "Caso uma feature (coluna) não seja utilizada ou usada muito pouco, podemos fazer um teste retirando ela da base de dados e ver se o resultado melhora ou não, com base nas métricas:\n",
    "\n",
    "- R2 ou RSME;\n",
    "- Velocidade do modelo;\n",
    "- Simplicidade do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6.7. Fazer ajustes no melhor modelo:\n",
    "\n",
    "Testamos cada mudança que fizermos no modelo para fazer um ajuste final.\n",
    "\n",
    "Analisamos se as features identificadas podem ser retiradas e treinamos e testamos o modelo, sempre comparando com o resultado original e o resultado anterior.\n",
    "\n",
    "Tudo isso com o objetivo de:\n",
    "- Encontrar uma possível melhoria no modelo;\n",
    "- Ver se conseguimos chegar no mesmo resultado ou mais próximo com um modelo mais simples e/ou mais rápido;\n",
    "- Fazer outros tipos de testes que tenham sido planejados (por exemplo, não retirar algum outlier ou coluna já excluida)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Modelo de Previsão na prática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Métricas de Avaliação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_teste serão os preços reais\n",
    "# previsao será o valor que foi previsto para podermos comparar \n",
    "# com o valor real\n",
    "\n",
    "def avaliar_modelo(nome_modelo, y_teste, previsao):\n",
    "    r2 = r2_score(y_teste, previsao)\n",
    "    rsme = np.sqrt(mean_squared_error(y_teste, previsao))\n",
    "    return f'Modelo {nome_modelo}:\\nR2: {r2}\\nRSME: {rsme}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eixo X são todas as variáveis. <br>\n",
    "Eixo Y é o que queremos prever.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Modelos a serem testados:\n",
    "\n",
    "    1. RandomForest\n",
    "    2. LinearRegression\n",
    "    3. Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_rf = RandomForestRegressor()\n",
    "modelo_lr = LinearRegression()\n",
    "modelo_et = ExtraTreesRegressor()\n",
    "\n",
    "modelos = {'RandomForest': modelo_rf,\n",
    "          'LinearRegression': modelo_lr,\n",
    "          'ExtraTrees': modelo_et\n",
    "          }\n",
    "\n",
    "y = df_encoded['price']\n",
    "X = df_encoded.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separar os dados em treino e teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "for nome_modelo, modelo in modelos.items():\n",
    "    #treinar\n",
    "    modelo.fit(X_train, y_train)\n",
    "    #testar\n",
    "    previsao = modelo.predict(X_test)\n",
    "    print(avaliar_modelo(nome_modelo, y_test, previsao))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Analisando o modelo em busca de melhoridas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = pd.DataFrame(modelo_rf.feature_importances_, X_train.columns)\n",
    "importancia = importancia.sort_values(by=0, ascending=False)\n",
    "display(importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "ax = sns.barplot(x=importancia.index, y=importancia[0])\n",
    "ax.tick_params(axis='x', rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Retirando coluna para tentar melhorar o modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is_business_travel_ready não teve muito impacto no modelo, então vamos excluir essa feature e testar o modelo sem ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_encoded = df_encoded.drop('is_business_travel_ready', axis=1) \n",
    "\n",
    "y = df_encoded['price']\n",
    "X = df_encoded.drop('price', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)\n",
    "\n",
    "for nome_modelo, modelo in modelos.items():\n",
    "    #treinar\n",
    "    modelo.fit(X_train, y_train)\n",
    "    #testar\n",
    "    previsao = modelo.predict(X_test)\n",
    "    print(avaliar_modelo(nome_modelo, y_test, previsao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importancia = pd.DataFrame(modelo_rf.feature_importances_, X_train.columns)\n",
    "importancia = importancia.sort_values(by=0, ascending=False)\n",
    "display(importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(importancia))\n",
    "\n",
    "dicionario = {'property_type_Apartment': 0, 'property_type_Bed and breakfast': 0, 'property_type_Condominium': 0, 'property_type_Guest suiteHouse': 0, 'property_type_Loft': 0, 'property_type_Townhouse': 0, 'property_type_Outros': 0, 'room_type_Entire home/apt': 0, 'room_type_Hotel room': 0, 'room_type_Private room': 0, 'room_type_Shared room': 0, 'bed_type_Airbed': 0, 'bed_type_Couch': 0, 'bed_type_Futon': 0, 'bed_type_Pull-out Sofa': 0, 'bed_type_Real Bed': 0, 'cancellation_policy_flexible': 0, 'cancellation_policy_moderate': 0, 'cancellation_policy_strict_14_with_grace_period': 0, 'cancellation_policy_super_strict': 0}\n",
    "\n",
    "print(len(dicionario))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado não mudou quase nada, mas como ficou mais simples (com uma coluna a menos) vamos manter assim.\n",
    "\n",
    "Fiz o teste também tirando o bed_type, mas aí o resultado deu uma leve piora.\n",
    "\n",
    "Considero essa acurácia de 64% um bom valor, levando em consideração o tamanho do banco de dados utilizado, já que, com pouco mais de 2 mil linhas, era um dataset relativamente pequeno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Deploy do projeto/modelo:\n",
    "\n",
    "É colocar em produção. É deixar o seu modelo disponível para outros usuários.\n",
    "\n",
    "1. Criar arquivo do modelo (joblib)\n",
    "2. Fazer o deploy com o streamlit\n",
    "3. Criar um novo arquivo python\n",
    "4. Importar o streamlit e criar o código\n",
    "5. Atribuir ao botão o carregamento do modelo\n",
    "6. Deploy finalizado\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 8.1. Criar arquivo joblib:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pegamos o valor X, que são as características do imóvel. Então vamos salvar essa base de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['price'] = y #estamos recolocando a coluna de preço na base de dados X\n",
    "\n",
    "X.to_csv('dados.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(modelo_rf, 'modelo.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse arquivo, não precisa treinar o modelo toda a vez que for fazer uma previsão. Iremos puxar esse arquivo que criamos quando for prever outro imóvel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.2 / 8.3. Criar um novo arquivo e fazer o deploy com streamlit:\n",
    "\n",
    "Como teremos que criar o novo arquivo, será nesse novo arquivo que continuaremos com a finalização deste pr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
